{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Detector for Real World Images\n",
    "\n",
    "## Project Intro/Objective\n",
    "The purpose of this project is to develope a multi-class classifier for digit detection and recognition in real- world images. The classifier should be able to perform two tasks: 1) detect digit in real-world images; 2) if a digit is detected, recognize it from 0 to 9. The classifier needs to be invariant to conditions including scale, location, font, pose, lighting, and noise and robust to complex scene background.\n",
    "\n",
    "### Methods Used\n",
    "* Maximally Stable Extremal Regions (MSERs)\n",
    "* Connected component splitting\n",
    "* Convolutional Neural Network (CNN)\n",
    "\n",
    "### Libraries\n",
    "* PyTorch \n",
    "* OpenCV\n",
    "* Numpy\n",
    "\n",
    "## Project Description\n",
    "The project followed a pipeline as shown in Fig.1:\n",
    "\n",
    "![image info](./figs/project_pipeline.png)\n",
    "\n",
    "<div align=\"center\"><b> Fig.1: Project Pipeline </b></div>\n",
    "\n",
    "### MSERs Pyramid\n",
    "MSERs pyramid is aimed at extending MSERs to be scale-invariant. The pyramid is created by detecting Region of Interests (ROI) i.e. MSERs in this case on the scaled images. The deteced ROIs are then applied Non-Maximum Suppression (NMS) according to Intersection over Union (IoU) score.\n",
    "\n",
    "### Connected Component Splitting\n",
    "The performance of MSERs is impacted by MSERs margin. A higher margin leads to good precision but poor recall, while a lower margin leads to better recall but error-connected components (ROIs that contain multiple characters). To balance between precision and recall, a novel method was employed which incorporats CNN and MSERs tree structure with a sliding window [[1]](#1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "This project used <a href=http://ufldl.stanford.edu/housenumbers/>Street View House Number</a> (SVHN) dataset [[2]](#2). This dataset originally serves the purpose of digit recognition and thus only contains digit images. In order to be used for digit detection, it must include non-digit images i.e. negative training samples.\n",
    "\n",
    "Let's create negaive training samples and add into original dataset. Then we split dataset into three sets: train, validation, and test. \n",
    "\n",
    "```python\n",
    "from data_create import create_train_val_test_data\n",
    "create_train_val_test_data(\n",
    "    'train_32x32.mat', 'digitStruct.json', './train', \n",
    "    'test_32x32.mat', 'digitStruct_test.json', './test'\n",
    ")\n",
    "```\n",
    "\n",
    "This process will output three files: \n",
    "* train_data.mat\n",
    "* val_data.mat\n",
    "* test_data.mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "This project considered two models: Text-Attentional CNN [[3]](#3) and VGG16 [[4]](#4). \n",
    "\n",
    "### Text-Attentional CNN\n",
    "Text-Attentional CNN is a deep neural network that particularly focuses on extracting text-related features from an image. It is a model for multi-task feature learning (MTL). Its architecture is shown in Fig.2:\n",
    "![image info](./figs/Text_Attentional_CNN.png)\n",
    "\n",
    "<p style=\"text-align: center;\">Fig.2: The Architecture of Text-Attentional CNN</p>\n",
    "\n",
    "### VGG16\n",
    "VGG16 is a very deep CNN consisting of 16 weight layers. Since the image size and number of classes used in VGG are much larger than this project, the model is fine-tuned to suit a smaller image size and 11 classes, including shrinking the kernel size of averaging pooling layer before fully-connected layer and decreasing the number of units of fully-connected layer.\n",
    "\n",
    "```python\n",
    "class  FineTuneVGG(nn.Module):\n",
    "    def __init__(self, freeze=True):\n",
    "        super(FineTuneVGG, self).__init__()\n",
    "        \n",
    "        self.model = models.vgg16_bn(pretrained=True)\n",
    "        if freeze:\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        # change output size and class number\n",
    "        self.model.avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "\n",
    "        for i, layer in enumerate(self.model.classifier):\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                self.model.classifier[i] = nn.Linear(\n",
    "                    in_features=(layer.in_features // 49),\n",
    "                    out_features=(layer.out_features // 49)\n",
    "                )\n",
    "        self.model.classifier[6] = nn.Linear(83, 11)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "The training is run for 2.5 × 105 iterations. For each iteration, weights are updated according to Stochastic Gradient Descent (SGD) with momentum. The best weights are determined according to the accuracy score over validation set. Over all iterations, the set of weights which can achieve the highest validation accuracy score is regarded as the best and is saved. The training is run to the end and no early stopping is applied. See Line 39 to 93 in train.py for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tunning\n",
    "Several experiments on learning rate, mini-batch size, and network variations have been performed to decide appropriate values and choice of CNN. \n",
    "```python\n",
    "    # batch size experiment\n",
    "    batch_sizes = [8, 16, 32, 64]\n",
    "    epoches = [10, 20, 40, 80]\n",
    "    batch_size_experiment(trainset, valset, zip(batch_sizes, epoches))\n",
    "\n",
    "    # learning rate experiment\n",
    "    lrs = [0.001, 0.005, 0.01]\n",
    "    learning_rate_experiment(trainset, valset, lrs)\n",
    "\n",
    "    # compare Text-Attentional CNN and VGG\n",
    "    network_variation_experiment(trainset, valset, False)\n",
    "\n",
    "    # compare pretrained and retrained weights of VGG\n",
    "    free_weights_experiement(trainset, valset, True)\n",
    "\n",
    "    # compare single-task mode and multi-task mode of Text-Attentional CNN\n",
    "    multi_task_experiment(trainset, valset, True)\n",
    "```\n",
    "\n",
    "These variations are evaluated according to their best accuracy scores over validation set. The results of the experiments are shown in Fig.3.\n",
    "\n",
    "![image info](./figs/lr.png)\n",
    "![image info](./figs/bs.png)\n",
    "![image info](./figs/nv.png)\n",
    "\n",
    "<p style=\"text-align: center;\">Fig.3: The Results of Hyperparameter Tunning Experiments</p>\n",
    "\n",
    "The best accuracy score for each variation is summarized as follows:\n",
    "\n",
    "Variation | Training | Validation\n",
    "--- | --- | --- \n",
    "LR0.001 | 99.66% | 97.43% \n",
    "LR0.005 | 98.96% | 97.23%\n",
    "LR0.01 | 99.47% | 97.30%\n",
    "BS8 | 98.90% | 97.24% \n",
    "BS16 | 99.66% | 97.43%\n",
    "BS32 | 99.88% | 97.52%\n",
    "BS64 | 99.91% | 97.40%\n",
    "VGG-baseline | 99.66% | 97.43%\n",
    "TextCNN-baseline | 97.81% | 94.90%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final model is configured as VGG16 with α = 0.001 and mini-batch size 16. The model is tested on SVHN-test and achieves 97.54% accuracy which is very closed to human performance (98% accuracy) on this dataset. The F-measure achieved is 69% with 73.7% precision and 64.5% recall. \n",
    "\n",
    "The classifier is able to detect and recognize digits with different scales, locations, orientations and illuminations as shown in Fig. 4a. But for complicated texts like closely-connected digits or digits with similar patterns as shown in Fig. 4b, they are undetected or misclassified due to the incorrect features extracted by MSERs detector.\n",
    "\n",
    "![image info](./figs/result.png)\n",
    "\n",
    "<p style=\"text-align: center;\">Fig.4: Performance of Digit Detector for Real World Images</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "<a id=\"1\">[1]</a> \n",
    "Huang,W., Qiao,Y., & Tang,X.(2014). \n",
    "Robust scene text detection with convolution neural network induced mser trees. \n",
    "In <em>European conference on computer vision</em> (pp. 497-511). Springer, Cham.<br/>\n",
    "<a id=\"2\">[2]</a>\n",
    "Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., & Ng, A. Y. (2011). Reading digits in natural images with unsupervised feature learning.\n",
    "<em>NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011</em>.<br/>\n",
    "<a id=\"3\">[3]</a>\n",
    "He, T., Huang, W., Qiao, Y., & Yao, J. (2016). \n",
    "Text-attentional convolutional neural network for scene text detection. \n",
    "<em>IEEE transactions on image processing</em>, 25(6), 2529-2541.<br/>\n",
    "<a id=\"4\">[4]</a> \n",
    "Simonyan, K., & Zisserman, A.(2015). \n",
    "Very deep convolutional networks for large-scale image recognition. \n",
    "arXiv preprint arXiv:1409.1556."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_proj",
   "language": "python",
   "name": "cv_proj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
